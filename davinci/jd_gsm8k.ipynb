{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用davinci-003推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  7 13:29:33 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 531.52                 Driver Version: 531.52       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                      TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 L...  WDDM | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   38C    P0               12W /  N/A|    902MiB /  8188MiB |      5%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      5616    C+G   ...am Files\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      8100    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      8988    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     10336    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     10456    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11640    C+G   ...on\\119.0.2151.44\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     12840    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     17040    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     18336    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     20656    C+G   ...2.0_x64__w2gh52qy24etm\\Nahimic3.exe    N/A      |\n",
      "|    0   N/A  N/A     27108    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     28284    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     28312    C+G   ...1\\extracted\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     29856    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     30384    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     32220    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     36404    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['HTTP_PROXY']=\"http://172.20.137.69:8001\"\n",
    "# os.environ['HTTPS_PROXY']=\"http://172.20.137.69:8001\"\n",
    "# os.environ['ALL_PROXY']=\"socks5://172.20.137.69:8000\"\n",
    "\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"../models/chatglm_6b\",repo_type=\"model\", trust_remote_code=True)\n",
    "# model = AutoModel.from_pretrained(\"../models/chatglm_6b\",trust_remote_code=True).half().cuda()\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from collections import Counter\n",
    "\n",
    "from utils import  load_data,getKey,write_json,mkpath\n",
    "\n",
    "Result_Folder = \"jx_result\"\n",
    "Err_Result_Folder = \"jx_err_result\"\n",
    "dataset = \"gsm8k\"\n",
    "datapath = \"./dataset/gsm8k/gsm8k_sup.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "时间: 1107_1329\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# 获取当前时间\n",
    "current_time = datetime.datetime.now()\n",
    "\n",
    "# 将时间格式化为文件夹名称的形式\n",
    "format_time = current_time.strftime(\"%m%d_%H%M\")\n",
    "\n",
    "print(\"时间:\", format_time)\n",
    "\n",
    "if not os.path.exists(Result_Folder):\n",
    "    mkpath(Result_Folder)\n",
    "if not os.path.exists(f\"{Result_Folder}/{dataset}\"):\n",
    "    mkpath(f'{Result_Folder}/{dataset}')\n",
    "if not os.path.exists(Err_Result_Folder):\n",
    "    mkpath(Err_Result_Folder)\n",
    "if not os.path.exists(f\"{Err_Result_Folder}/{dataset}\"):\n",
    "    mkpath(f'{Err_Result_Folder}/{dataset}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are four schools competing at a basketball tournament. Each school has sent a girls’ basketball team and a boys’ basketball team and each team has 5 players each. Each school has also sent a coach for each team. In total, how many people have all of the schools sent? 48.0\n",
      "问题个数：1\n",
      "答案个数：1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('There are four schools competing at a basketball tournament. Each school has sent a girls’ basketball team and a boys’ basketball team and each team has 5 players each. Each school has also sent a coach for each team. In total, how many people have all of the schools sent?',\n",
       " 48.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question, answer, ids = load_data(datapath,dataset)\n",
    "assert len(question) == len(answer), \"输入长度不一致\"\n",
    "assert len(question) == len(ids),\"输入长度不一致\"\n",
    "data_scale = len(answer)\n",
    "print(f\"问题个数：{len(question)}\")\n",
    "print(f\"答案个数：{len(answer)}\")\n",
    "\n",
    "question[0],answer[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单条prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 两个list分别代表201和202的所有问题的cots;每个列表是n个字典，字典内包含cots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_prompt import get_prompt,construct_input\n",
    "from prediction_runner import basic_runner\n",
    "from extracter import extract_answer,get_precision\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "engine = \"text-davinci-003\"\n",
    "max_length_cot = 512\n",
    "key_index = 0\n",
    "\n",
    "\n",
    "def get_paths(prompt_id,prompt_type,path_num):\n",
    "    res = []\n",
    "    _, prompt = get_prompt(prompt_id=prompt_id,type=prompt_type)\n",
    "    # print(prompt)\n",
    "    Predict_File = f'{Result_Folder}/{dataset}/{format_time}-Type_{prompt_type}-{prompt_id}-Num_{data_scale}-{path_num}.json'\n",
    "    Decoder_Error_File = f'{Err_Result_Folder}/{dataset}/{format_time}-Type_{prompt_type}-{prompt_id}-{path_num}.json'\n",
    "    pred_list = []\n",
    "    for idx, element in tqdm(enumerate(question)):\n",
    "        inputs = construct_input(prompt, element)\n",
    "        try:\n",
    "            get_result, pred_list, error_msg = basic_runner(engine, inputs, max_length_cot, key_index,path_num)\n",
    "            res.append({element:pred_list})\n",
    "        except Exception as e:\n",
    "            print(\"没有获取到答案！\\n\")\n",
    "            decode_error_data = {\n",
    "                'question': question[idx],\n",
    "                'answer':answer[idx]\n",
    "            }\n",
    "            write_json(decode_error_data, Decoder_Error_File)\n",
    "            print(\n",
    "                f\"an error raised when predicting (question id: {ids[idx]}). \"\n",
    "                f\"ERROR: {getattr(e.__class__, '__name__')}:{str(e)}\"\n",
    "            )\n",
    "            continue   \n",
    "        # print(\"pred_list:\",pred_list)        \n",
    "        if not get_result:\n",
    "            print(\n",
    "                f\"not get predicted result (question id: {ids[idx]}).\"\n",
    "                f\"ERROR Message: {error_msg if error_msg else None}\"\n",
    "            )\n",
    "            continue\n",
    "        json_data = {\n",
    "                        \"ID\": ids[idx],\n",
    "                        \"question\": question[idx],\n",
    "                        \"chain-of-thought\": pred_list,\n",
    "                        # \"pred\": pred_answer,\n",
    "                        \"answer\": answer[idx],\n",
    "                        # \"ans\": ans\n",
    "                    }    \n",
    "        write_json(json_data, Predict_File)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_all_paths(prompt_id_list,path_num,prompt_type):\n",
    "    res = []\n",
    "    for id in prompt_id_list:\n",
    "        paths = get_paths(prompt_id=id,prompt_type=prompt_type,path_num=path_num)\n",
    "        res.append(paths)\n",
    "    return res\n",
    "\n",
    "def get_combined_paths(res_list:list):\n",
    "    result = []\n",
    "    assert len(res_list) == 2,\"prompt限制两条\"\n",
    "    paths_1 = res_list[0]\n",
    "    paths_2 = res_list[1]\n",
    "    # print(len(paths_1))\n",
    "    assert len(paths_1) == len(question) == len(paths_2),\"path个数和问题个数不匹配\"\n",
    "\n",
    "    for j in range(len(paths_1)):\n",
    "        for k,v in paths_1[j].items():\n",
    "            k1,v1 = k,v\n",
    "        for k,v in paths_2[j].items():\n",
    "            k2,v2 = k,v\n",
    "        # print('----------------')\n",
    "        # print(k1)\n",
    "        # print(k2)\n",
    "        # print(question[j])\n",
    "        # print('----------------')\n",
    "        assert k1 == k2 == question[j]\n",
    "        temp = {\n",
    "            \"question\" : k1,\n",
    "            \"paths\" : v1 + v2,\n",
    "            \"answer\" : answer[j]\n",
    "        }\n",
    "            \n",
    "        result.append(temp)\n",
    "    return result\n",
    "\n",
    "# test_a = [[{'a':[1]},{'b':[2]}],[{'a':[3]},{'b':[4]}]]\n",
    "# get_combined_paths(test_a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "# f1 = []\n",
    "# f2 = []\n",
    "# with open('./jx_result/gsm8k/1101_2355-Type_1-201-Num_953-5.json','r',encoding='utf-8') as f11:\n",
    "#     f1 = json.load(f11)\n",
    "# with open('./jx_result/gsm8k/1106_1719-Type_1-202-Num_953-5.json','r',encoding='utf-8') as f22:\n",
    "#     f2 = json.load(f22)    \n",
    "# len(f1),len(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1 = []\n",
    "# t2 = []\n",
    "# for i in range(len(f1)):\n",
    "#     temp1 = {}\n",
    "#     temp2 = {}\n",
    "#     q1 = f1[i]['question']\n",
    "#     v1 = f1[i]['chain-of-thought']\n",
    "#     temp1[q1] = v1\n",
    "#     t1.append(temp1)\n",
    "#     q2 = f2[i]['question']\n",
    "#     v2 = f2[i]['chain-of-thought']\n",
    "#     temp2[q2] = v2\n",
    "#     t2.append(temp2)\n",
    "# all_paths = []\n",
    "# all_paths.append(t1)\n",
    "# all_paths.append(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_paths = get_combined_paths(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.54s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt_id_list = [202]\n",
    "path_num = 5\n",
    "prompt_type = 1\n",
    "\n",
    "all_paths = get_all_paths(prompt_id_list=prompt_id_list,path_num=path_num,prompt_type=prompt_type)\n",
    "# res_paths = get_combined_paths(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(prompt_id_list) == 2\n",
    "ids = prompt_id_list[0] +prompt_id_list[1]\n",
    "\n",
    "# temp_p = f'{Result_Folder}/{dataset}/temp-{format_time}-Type_{prompt_type}-{ids}-Num_{data_scale}-{path_num}.json'\n",
    "temp_p = './jx_result/gsm8k/temp-1101_1812-Type_1-201-Num_266-5.json'\n",
    "write_json(res_paths,path=temp_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用chatGLM抽取答案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# temp_p = \"./jx_result/gsm8k/temp-1031_0933-Type_1-403-Num_100-5.json\"\n",
    "with open(temp_p,'r') as f:\n",
    "    data = json.load(f)\n",
    "len(data),data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 抽取答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatGLM(text,history):\n",
    "    res,history  = model.chat(tokenizer,text,history)\n",
    "#     print(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "induce = \"Please extract the answer from the text.\\n[Output]: The answer is xxx.\\n\"\n",
    "\n",
    "for item in data:\n",
    "    cots = item['paths']\n",
    "    ans = []\n",
    "    for cot in cots:\n",
    "        induce_prompt = induce + '[Text]:\\n' + cot\n",
    "        try:\n",
    "            res = chatGLM(induce_prompt,[])\n",
    "            ans.append(res)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    item['answers'] = ans    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_number(text:str):\n",
    "    pattern = r'(?<=answer\\s).*?(\\d+(?:\\.\\d+)?)'\n",
    "    match = re.search(pattern=pattern,string=text)\n",
    "    if match:\n",
    "        answer = float(match.group(1))\n",
    "    else:\n",
    "        answer = None\n",
    "    return answer\n",
    "\n",
    "\n",
    "def extract_answer(text: str):\n",
    "    \n",
    "    pattern_1 = r'\\d+(?:\\.\\d+)?'\n",
    "    # 尝试直接从cot中抽取答案\n",
    "    answer = extract_number(text)\n",
    "    # 如果抽不出来，则将其再次输入chatGLM-6b,得到新的text\n",
    "    if answer == None:\n",
    "        try:\n",
    "            induce_prompt = induce + '[Text]:\\n' + text\n",
    "            text = chatGLM(induce_prompt,[])\n",
    "            answer = extract_number(text)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    # 如果仍旧抽不出来，则区第一个出现的数字\n",
    "    if answer == None:    \n",
    "        match = re.search(pattern=pattern_1,string=text)\n",
    "        if match:\n",
    "            answer = float(match.group())\n",
    "            # print(\"Answer:\", answer)\n",
    "        else:\n",
    "            answer =None\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import  tqdm\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    ans = []\n",
    "    answers = data[i]['answers']\n",
    "    for item in answers:\n",
    "        answer = extract_answer(item)\n",
    "        ans.append(answer)\n",
    "    data[i]['answers'] = ans\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import write_json\n",
    "\n",
    "prompt_id_list = [201,202]\n",
    "\n",
    "assert len(prompt_id_list) == 2\n",
    "ids = prompt_id_list[0] +prompt_id_list[1]\n",
    "\n",
    "res_p = f'{Result_Folder}/{dataset}/res-{format_time}-Type_{prompt_type}-{ids}-Num_{data_scale}-{path_num}.json'\n",
    "# res_p = \"./jx_result/gsm8k/res-1031_0933-Type_1-403-Num_100-5.json\"\n",
    "\n",
    "write_json(data,path=res_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(res_p,'r',encoding='utf-8') as f:\n",
    "    res_data = json.load(f)\n",
    "len(res_data),res_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for item in res_data:\n",
    "    answers = item['answers']\n",
    "    jx = Counter(answers).most_common(1)[0][0]\n",
    "    item['pred_answer'] = jx\n",
    "\n",
    "data[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 0\n",
    "c2 = 0\n",
    "for item in res_data:\n",
    "    pred = item['pred_answer']\n",
    "    gold = item['answer']\n",
    "    if pred:\n",
    "        if float(pred) == float(gold):\n",
    "            item['ans'] = True\n",
    "            c1 += 1\n",
    "        else:\n",
    "            item['ans'] = False\n",
    "            c2 += 1\n",
    "    else:\n",
    "        c2 += 1\n",
    "assert c1 + c2 == len(data)\n",
    "c1,c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = res_p.replace('res-','ses-')\n",
    "\n",
    "write_json(res_data,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = './jx_result/gsm8k/1018_1021-Type_1-303-Num_100-0.json'\n",
    "\n",
    "data = []\n",
    "with open(path,'r') as f:\n",
    "   for line in f:\n",
    "        data.append(line)\n",
    "len(data)\n",
    "\n",
    "count = 0\n",
    "pos = 0\n",
    "neg = 0\n",
    "for item in data:\n",
    "    if \"\\\"ans\\\":\" in item:\n",
    "        count+=1;\n",
    "        if \"true\" in item:\n",
    "            pos+=1\n",
    "        else:\n",
    "            neg+=1\n",
    "assert count == pos + neg,\"统计错误\"\n",
    "print(count,pos)\n",
    "print(pos/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Brenda will have a total of $450 after 3 years. This can be calculated using the formula for simple interest: \\n\\nTotal Amount = Principal Amount + Interest Earned \\n\\nTotal Amount = 300 + (300 x 0.75 x 3) \\n\\nTotal Amount = 300 + 225 \\n\\nTotal Amount = $450')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(203+199+198)/900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.397+0.354+0.5)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(184+33)/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "199/300"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
